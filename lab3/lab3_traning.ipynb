{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/yuhu/Desktop/p4-Speech/Speech-Speaker-Recognition/lab1')\n",
    "sys.path.append('/Users/yuhu/Desktop/p4-Speech/Speech-Speaker-Recognition/lab2')\n",
    "from lab1_proto import *\n",
    "from lab2_proto import *\n",
    "from tqdm import trange\n",
    "import os\n",
    "import numpy as np \n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.backend import one_hot\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 1 2]\n [3 4 5]\n [6 7 8]]\n[[-1.22474487 -1.22474487 -1.22474487]\n [ 0.          0.          0.        ]\n [ 1.22474487  1.22474487  1.22474487]]\n"
    }
   ],
   "source": [
    "a = np.arange(9).reshape((3,3))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(a)\n",
    "print(a)\n",
    "print(scaler.transform(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneHMMs_all = np.load('/Users/yuhu/Desktop/p4-Speech/Speech-Speaker-Recognition/lab2/lab2_models_all.npz',allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs_all.keys())\n",
    "nstates = {phone: phoneHMMs_all[phone]['means'].shape[0] for phone in phones}\n",
    "stateList = [ph + '_' + str(i) for ph in phones for i in range(nstates[ph])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=np.load('train_nondynamic.npz',allow_pickle=1)\n",
    "X_train_lmfcc = traindata['lmfcc']\n",
    "X_train_mspec = traindata['mspec']\n",
    "Y_train = traindata['Y']\n",
    "Y_train = np.squeeze(one_hot(Y_train,len(stateList)))\n",
    "\n",
    "valdata=np.load('val_nondynamic.npz',allow_pickle=1)\n",
    "X_val_lmfcc = valdata['lmfcc']\n",
    "X_val_mspec = valdata['mspec']\n",
    "Y_val = valdata['Y']\n",
    "Y_val = np.squeeze(one_hot(Y_val,len(stateList)))\n",
    "\n",
    "testdata=np.load('test_nondynamic.npz',allow_pickle=1)\n",
    "X_test_lmfcc = testdata['lmfcc']\n",
    "X_test_mspec = testdata['mspec']\n",
    "Y_test = testdata['Y']\n",
    "Y_test = np.squeeze(one_hot(Y_test,len(stateList)))\n",
    "\n",
    "traindata_d=np.load('train_dynamic.npz',allow_pickle=1)\n",
    "X_train_lmfcc_d = traindata_d['lmfcc']\n",
    "X_train_mspec_d = traindata_d['mspec']\n",
    "Y_train_d = traindata_d['Y']\n",
    "Y_train_d = np.squeeze(one_hot(Y_train_d,len(stateList)))\n",
    "\n",
    "valdata_d=np.load('val_dynamic.npz',allow_pickle=1)\n",
    "X_val_lmfcc_d = valdata_d['lmfcc']\n",
    "X_val_mspec_d = valdata_d['mspec']\n",
    "Y_val_d = valdata_d['Y']\n",
    "Y_val_d = np.squeeze(one_hot(Y_val_d,len(stateList)))\n",
    "\n",
    "testdata_d=np.load('test_dynamic.npz',allow_pickle=1)\n",
    "X_test_lmfcc_d = testdata_d['lmfcc']\n",
    "X_test_mspec_d = testdata_d['mspec']\n",
    "Y_test_d = testdata_d['Y']\n",
    "Y_test_d = np.squeeze(one_hot(Y_test_d,len(stateList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train,X_val,X_test): \n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train=scaler.transform(X_train)\n",
    "  X_val=scaler.transform(X_val)\n",
    "  X_test=scaler.transform(X_test)\n",
    "\n",
    "  return X_train,X_val,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lmfcc,X_val_lmfcc,X_test_lmfcc=normalize(X_train_lmfcc,X_val_lmfcc,X_test_lmfcc)\n",
    "X_train_mspec_d,X_val_mspec_d,X_test_mspec_d=normalize(X_train_mspec_d,X_val_mspec_d,X_test_mspec_d)\n",
    "X_train_mspec,X_val_mspec,X_test_mspec=normalize(X_train_mspec,X_val_mspec,X_test_mspec)\n",
    "X_train_lmfcc_d,X_val_lmfcc_d,X_test_lmfcc_d=normalize(X_train_lmfcc_d,X_val_lmfcc_d,X_test_lmfcc_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape,n_states):\n",
    "  Inp = Input(input_shape)\n",
    "  x = Dense(256,activation='relu')(Inp)\n",
    "  x = Dense(256,activation='relu')(x)\n",
    "  x = Dense(256,activation='relu')(x)\n",
    "  y = Dense(n_states,activation='softmax')(x)\n",
    "  model = Model(inputs=Inp,outputs=y)\n",
    "  print(model.summary())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 13)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               3584      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_3 (Dense)              (None, 61)                15677     \n=================================================================\nTotal params: 150,845\nTrainable params: 150,845\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model_lmfcc = get_model(X_train_lmfcc[-1].shape,len(stateList))\n",
    "model_lmfcc.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1487243 samples\nEpoch 1/20\n1487243/1487243 [==============================] - 16s 10us/sample - loss: 1.7210 - accuracy: 0.4904\nEpoch 2/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.5949 - accuracy: 0.5167\nEpoch 3/20\n1487243/1487243 [==============================] - 30s 20us/sample - loss: 1.5570 - accuracy: 0.5259\nEpoch 4/20\n1487243/1487243 [==============================] - 26s 17us/sample - loss: 1.5324 - accuracy: 0.5319\nEpoch 5/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 1.5142 - accuracy: 0.5362\nEpoch 6/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 1.5008 - accuracy: 0.5396\nEpoch 7/20\n1487243/1487243 [==============================] - 22s 15us/sample - loss: 1.4891 - accuracy: 0.5430\nEpoch 8/20\n1487243/1487243 [==============================] - 21s 14us/sample - loss: 1.4797 - accuracy: 0.5456\nEpoch 9/20\n1487243/1487243 [==============================] - 23s 15us/sample - loss: 1.4721 - accuracy: 0.5470\nEpoch 10/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 1.4649 - accuracy: 0.5491\nEpoch 11/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.4587 - accuracy: 0.5506\nEpoch 12/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 1.4531 - accuracy: 0.5520\nEpoch 13/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 1.4481 - accuracy: 0.5536\nEpoch 14/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 1.4438 - accuracy: 0.5548\nEpoch 15/20\n1487243/1487243 [==============================] - 17s 12us/sample - loss: 1.4400 - accuracy: 0.5558\nEpoch 16/20\n1487243/1487243 [==============================] - 17s 12us/sample - loss: 1.4362 - accuracy: 0.5565\nEpoch 17/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 1.4329 - accuracy: 0.5576\nEpoch 18/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.4297 - accuracy: 0.5584\nEpoch 19/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 1.4268 - accuracy: 0.5596\nEpoch 20/20\n1487243/1487243 [==============================] - 21s 14us/sample - loss: 1.4239 - accuracy: 0.5597\n"
    }
   ],
   "source": [
    "his_lmffc = model_lmfcc.fit(X_train_lmfcc,Y_train,batch_size=256,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 91)]              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               23552     \n_________________________________________________________________\ndense_5 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_6 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_7 (Dense)              (None, 61)                15677     \n=================================================================\nTotal params: 170,813\nTrainable params: 170,813\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model_lmfcc_d = get_model(X_train_lmfcc_d[-1].shape,len(stateList))\n",
    "model_lmfcc_d.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1487243 samples\nEpoch 1/20\n1487243/1487243 [==============================] - 17s 12us/sample - loss: 0.7769 - accuracy: 0.7441\nEpoch 2/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 0.6086 - accuracy: 0.7915\nEpoch 3/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 0.5628 - accuracy: 0.8061\nEpoch 4/20\n1487243/1487243 [==============================] - 14s 10us/sample - loss: 0.5363 - accuracy: 0.8146\nEpoch 5/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 0.5181 - accuracy: 0.8204\nEpoch 6/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 0.5044 - accuracy: 0.8245\nEpoch 7/20\n1487243/1487243 [==============================] - 21s 14us/sample - loss: 0.4939 - accuracy: 0.8279\nEpoch 8/20\n1487243/1487243 [==============================] - 19s 13us/sample - loss: 0.4846 - accuracy: 0.8307\nEpoch 9/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 0.4769 - accuracy: 0.8331\nEpoch 10/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 0.4704 - accuracy: 0.8349\nEpoch 11/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 0.4645 - accuracy: 0.8369\nEpoch 12/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 0.4595 - accuracy: 0.8387\nEpoch 13/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 0.4556 - accuracy: 0.8397\nEpoch 14/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 0.4513 - accuracy: 0.8412\nEpoch 15/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 0.4476 - accuracy: 0.8426\nEpoch 16/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 0.4449 - accuracy: 0.8433\nEpoch 17/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 0.4415 - accuracy: 0.8441\nEpoch 18/20\n1487243/1487243 [==============================] - 17s 12us/sample - loss: 0.4388 - accuracy: 0.8452\nEpoch 19/20\n1487243/1487243 [==============================] - 19s 13us/sample - loss: 0.4358 - accuracy: 0.8465\nEpoch 20/20\n1487243/1487243 [==============================] - 18s 12us/sample - loss: 0.4327 - accuracy: 0.8473\n"
    }
   ],
   "source": [
    "his_lmffc_d = model_lmfcc_d.fit(X_train_lmfcc_d,Y_train_d,batch_size=256,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 40)]              0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 256)               10496     \n_________________________________________________________________\ndense_21 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_22 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_23 (Dense)             (None, 61)                15677     \n=================================================================\nTotal params: 157,757\nTrainable params: 157,757\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model_mspec = get_model(X_train_mspec[-1].shape,len(stateList))\n",
    "model_mspec.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1487243 samples\nEpoch 1/20\n1487243/1487243 [==============================] - 16s 10us/sample - loss: 1.7238 - accuracy: 0.4901\nEpoch 2/20\n1487243/1487243 [==============================] - 14s 9us/sample - loss: 1.5519 - accuracy: 0.5279\nEpoch 3/20\n1487243/1487243 [==============================] - 13s 9us/sample - loss: 1.4954 - accuracy: 0.5418\nEpoch 4/20\n1487243/1487243 [==============================] - 14s 9us/sample - loss: 1.4613 - accuracy: 0.5506\nEpoch 5/20\n1487243/1487243 [==============================] - 14s 9us/sample - loss: 1.4376 - accuracy: 0.5563\nEpoch 6/20\n1487243/1487243 [==============================] - 14s 10us/sample - loss: 1.4196 - accuracy: 0.5610\nEpoch 7/20\n1487243/1487243 [==============================] - 14s 9us/sample - loss: 1.4049 - accuracy: 0.5649\nEpoch 8/20\n1487243/1487243 [==============================] - 14s 9us/sample - loss: 1.3926 - accuracy: 0.5679\nEpoch 9/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.3831 - accuracy: 0.5706\nEpoch 10/20\n1487243/1487243 [==============================] - 17s 11us/sample - loss: 1.3744 - accuracy: 0.5728\nEpoch 11/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3661 - accuracy: 0.5750\nEpoch 12/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3591 - accuracy: 0.5762\nEpoch 13/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.3532 - accuracy: 0.5781\nEpoch 14/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3477 - accuracy: 0.5796\nEpoch 15/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3425 - accuracy: 0.5809\nEpoch 16/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.3374 - accuracy: 0.5821\nEpoch 17/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.3335 - accuracy: 0.5834\nEpoch 18/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3295 - accuracy: 0.5842\nEpoch 19/20\n1487243/1487243 [==============================] - 16s 11us/sample - loss: 1.3256 - accuracy: 0.5852\nEpoch 20/20\n1487243/1487243 [==============================] - 15s 10us/sample - loss: 1.3228 - accuracy: 0.5862\n"
    }
   ],
   "source": [
    "his_mspec = model_mspec.fit(X_train_mspec,Y_train,batch_size=256,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_8 (InputLayer)         [(None, 280)]             0         \n_________________________________________________________________\ndense_28 (Dense)             (None, 256)               71936     \n_________________________________________________________________\ndense_29 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_30 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndense_31 (Dense)             (None, 61)                15677     \n=================================================================\nTotal params: 219,197\nTrainable params: 219,197\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "model_mspec_d = get_model(X_train_mspec_d[-1].shape,len(stateList))\n",
    "model_mspec_d.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_mspec_d = model_mspec.fit(X_train_mspec_d,Y_train,batch_size=256,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda3eac4cbd41724e1399becce7716536d7",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}